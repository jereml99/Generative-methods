{"cells":[{"cell_type":"markdown","metadata":{"id":"F16XNUKI9vya"},"source":["# 02563 Generative Methods for Comptuer Graphics - Spring 2025\n","\n","The purpose of this exercise is to familiarize yourself with neural shape representation. This is a relatively new research field that has gained significant interest over the past ~6 years. We will be examining one of the most influential papers in this field, namely DeepSDF, which introduces the Neural Implicit Surface Representation. In this paper, the authors approximate the Signed Distance Field (SDF) for various shapes using a simple neural network called a Multilayer Perceptron (MLP). This approach allows them to generate 3D shapes, interpolate smoothly between different shapes, and auto-complete partial shapes.\n","\n","In this exercise, you will first learn how to extract a discrete triangle mesh from a pretrained MLP that approximates the SDF of a 3D shape. Next, you will explore how to interpolate between two different 3D shapes using a pretrained MLP that has been trained to approximate the SDF of both shapes. Finally, you will train your own MLP to approximate the SDF of a different set of two shapes and evaluate its performance in interpolating between them. To accomplish this, you must complete the dataloader, which generates the training data for the network, and then train the network. Lastly, you will answer a few questions regarding Neural Implicit Surface Representations.\n","\n","This notebooks builds on the following papers:\n","\n","1) <a href=\"https://arxiv.org/abs/1901.05103\">DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation</a> by Jeong Joon Park, Peter Florence, Julian Straub, Richard Newcombe, Steven Lovegrove <br><br>\n","2) <a href=\"https://nv-tlabs.github.io/lip-mlp/\">Learning Smooth Neural Functions\n","via Lipschitz Regularization</a> by Hsueh-Ti Derek Liu, Francis Williams, Alec Jacobson, Sanja Fidler, Or Litany\n","\n","This notebook is meant to be run on Google Colab, so you can utilize their GPUs. However, it should also work, if you want to run it locally. Just make sure that you have <a href=\"https://pytorch.org\">PyTorch</a> and <a href=\"https://github.com/janba/GEL\">PyGEL</a> installed. It should also be possible to run this notebook without access to a GPU - it will just be a little bit slower.\n","\n","If you are not familiar with PyGEL, take a look at this <a href=\"http://www2.compute.dtu.dk/projects/GEL/PyGEL/\">introduction</a> and <a href=\"http://www2.compute.dtu.dk/projects/GEL/PyGEL/PyGEL/pygel3d/hmesh.html\">the reference documentation</a>. Note especially the _m.triangulate_face(f,mode='v')_ function.\n","\n","The bunny and Spot were used courtesy of the Stanford 3D scanning repository and Professor Keenan Crane."]},{"cell_type":"markdown","metadata":{"id":"SdB21e8k_Opb"},"source":["## Setup Initial Configurations\n","Here you install the needed Python packages as well as mouting your Google drive, so you can access the content in the directory of the notebook from the notebook. If you run this notebook on your local machine, you don't have to do this."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AM_pRkgn9Urd"},"outputs":[],"source":["# Install the right packages - You need to run this cell, if you run this notebook on Google Colab\n","!apt-get install libglu1 libgl1 &> /dev/null\n","!pip install PyGEL3D &> /dev/null\n","!pip3 uninstall --yes torch torchaudio torchvision torchtext torchdata &> /dev/null\n","!pip3 install torch torchaudio torchvision torchtext torchdata &> /dev/null\n","!pip3 install plotly==5.24.1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7oR9gSdyFos2"},"outputs":[],"source":["# Mount (Connect) your google home drive - Essentially, allow Google to find and retrieve the files\n","from google.colab import drive\n","drive.mount('/content/drive')\n","# If you want to check that you mounted the drive correctly, you can use the command below to see what is in your drive\n","#!ls drive/'My Drive'\n","\n","# Set directory\n","drive_path = 'drive/My Drive/Ex_Neural_Implicit_Surfaces'\n","\n","import sys\n","sys.path.append(drive_path)"]},{"cell_type":"code","source":["# Import ptyhon packages and helper functions from the \"utils\" python file\n","from utils import *\n","\n","# Load data\n","m_spot = hmesh.obj_load(os.path.join(drive_path, \"spot.obj\"))\n","m_bunny = hmesh.obj_load(os.path.join(drive_path,\"bunny.obj\"))\n","m_wolf = hmesh.obj_load(os.path.join(drive_path,\"wolf.obj\"))"],"metadata":{"id":"fHBz4zFBVlGS"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XAPmtd559UxI"},"outputs":[],"source":["# Select CPU or GPU\n","# If device is cpu, then go to menu and select Runtime -> Change runtime type -> GPU and restart the notebook by going to Runtime -> Restart session.\n","# If it prints cuda:0, then you have access to a GPU\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(\"Using device:\", device)"]},{"cell_type":"markdown","metadata":{"id":"wggqhXT-cRa_"},"source":["## Display one of the meshes (Spot the cow)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kJPKP8NAH6CL"},"outputs":[],"source":["display_meshes(m_spot)"]},{"cell_type":"markdown","metadata":{"id":"wGZ4kjuC6vn3"},"source":["#### Set up the hyper parameters for the network. You can change these, if you like"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-FjoB2ri6xws"},"outputs":[],"source":["latent_vector_size = 256\n","no_sampled_bounding_box_points = 1000\n","no_sampled_surface_points = 2000\n","mesh_resolution = 80\n","network_hidden_layers = [512,512,512,512,512,512,512,512]\n","network_leanring_rate = 0.0001\n","latent_vector_learning_rate = 0.001\n","num_interpolations = 5\n","num_epochs = 10000\n","lipschitz_cosntant = 0.000001\n","pretrained_model = os.path.join(drive_path,\"pretrained_model.pt\") # A pretrained model, which approximates the SDF of spot and the wolf.\n","your_best_model = os.path.join(drive_path,\"your_best_model.pt\") # When you train the network, the model is saved as \"your_best_model.pt\""]},{"cell_type":"markdown","source":["## Part 1: Extract the mesh from pretrained network\n","In this part of the exercise, you are given a pretrained network that has been trained on Spot and the Wolf. Your task is to extract a triangle mesh from this learned representation"],"metadata":{"id":"sIj2SrwUPcuX"}},{"cell_type":"code","source":["# Network\n","net = Network(input_size=latent_vector_size + 3, hidden_layers=network_hidden_layers, device=device)\n","net = net.to(device)\n","# Latent vectors\n","lv = Latent_vectors(0.0, 0.01, latent_vector_size, 2, device)"],"metadata":{"id":"XWA9equg12Hc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the pretrained model\n","model = pretrained_model # Use the pretrained model\n","if os.path.exists(model):\n","    checkpoint = torch.load(model,map_location=device)\n","    net.load_state_dict(checkpoint['net_state_dict'])\n","    net.normalize_params()\n","    net.eval()\n","    latent_vectors = checkpoint['latent_vectors']\n","else:\n","    print(\"Error: The pretrained model does not exist\")"],"metadata":{"id":"wZkEXjFZ12EJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def inference(net : Network, latent_vector : torch.Tensor, mesh_resolution : int, device : torch.device) -> hmesh.Manifold:\n","    net.normalize_params()\n","    net.eval()\n","\n","    # NB: When inputting the latent vector and 3D point into the network,\n","    # the order should be: [3D_point,latent_vector]\n","    x = np.linspace(-1, 1, mesh_resolution)\n","    y = np.linspace(-1, 1, mesh_resolution)\n","    z = np.linspace(-1, 1, mesh_resolution)\n","\n","    # Create a meshgrid\n","    X, Y, Z = np.meshgrid(x, y, z, indexing='ij')\n","\n","    # Flatten the grid to get a list of points\n","    points = np.vstack([X.ravel(), Y.ravel(), Z.ravel()]).T\n","\n","    points = torch.from_numpy(points).to(device)\n","\n","    network_input = torch.hstack((points, latent_vector.repeat(len(points),1))).float()\n","\n","    grid_SDF = net.eval_forward(network_input).reshape(mesh_resolution, mesh_resolution, mesh_resolution)\n","\n","    grid_SDF = grid_SDF.cpu().detach().numpy()\n","\n","    # Function that extracts an mesh \"m_recovered\" from a point grid\n","    # Input is a point grid of SDF values called grid_SDF\n","    m_recovered = hmesh.volumetric_isocontour(grid_SDF, make_triangles=True, high_is_inside=False)\n","\n","    # Function that maps the positions of the point grid to the original space\n","    # dims is the dimensions of your point grid\n","    xform = XForm(-1.0, 1.0, (mesh_resolution, mesh_resolution, mesh_resolution))\n","\n","    pos = m_recovered.positions()\n","    for v in m_recovered.vertices():\n","        pos[v] = xform.map(pos[v])\n","\n","    return m_recovered"],"metadata":{"id":"T1mB8uVg12A3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mesh = m_spot # Select a mesh\n","latent_vector = latent_vectors[0] # Find the latent vector belonging to that mesh\n","\n","m_recovered = inference(net, latent_vector, mesh_resolution, device)\n","\n","# Save the recovered mesh\n","hmesh.obj_save(os.path.join(drive_path,\"m_recovered.obj\"),m_recovered)\n","\n","# Display the ground truth mesh in red and the reconstructed mesh in blue\n","if (m_recovered.no_allocated_vertices() != 0):\n","    #display_meshes(m_recovered, mesh) # If you want to display both the reconstructed mesh and the original mesh\n","    display_meshes(m_recovered) # If you only want to display the reconstructed mesh"],"metadata":{"id":"95k3f9h11178"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Part 2: Interpolate between the shapes\n","Use your method that extracts a triangle mesh from the learned signed distance field to interpolate between the two shapes using the latent vectors for the shapes"],"metadata":{"id":"irS64fPr2b2d"}},{"cell_type":"code","source":["interpolated_meshes = [] # A list that appends the interpolated meshes\n","\n","t = np.linspace(0,1,num_interpolations)\n","\n","for ii in range(num_interpolations):\n","\n","    interpolated_latent_vector = (1.0 - t[ii]) * latent_vectors[0] + t[ii] * latent_vectors[1] # The interpolated latent vector\n","\n","    interpolated_mesh = inference(net, interpolated_latent_vector, mesh_resolution, device)\n","    hmesh.obj_save(os.path.join(drive_path,\"m_interpolated_\" + str(ii) + \".obj\"),interpolated_mesh)\n","    interpolated_meshes.append( interpolated_mesh )"],"metadata":{"id":"7i2770Yd11we"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# If you run this notebook locally on your own machine, you can run the code in this cell.\n","#viewer = gl.Viewer()\n","#for i in range(num_interpolations):\n","#    viewer.display(interpolated_meshes[i],mode='w')\n","#del viewer"],"metadata":{"id":"EH2QjZvA2ajx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display your approximation of the bunny as a mesh\n","\n","#m_bunny_approximated = interpolated_meshes[0]\n","#display_meshes(m_bunny, m_bunny_approximated)"],"metadata":{"id":"rzoSj45M5bVR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display your approximation of the Wolf as a mesh\n","\n","#m_wolf_approximated = interpolated_meshes[-1]\n","#display_meshes(m_wolf, m_wolf_approximated)"],"metadata":{"id":"i1AtItsI5ejI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display your approximation of the shape that is half bunny, half wolf\n","\n","#m_half_bunny_wolf_approximated = interpolated_meshes[math.floor(len(interpolated_meshes)/2)]\n","#display_meshes(m_half_bunny_wolf_approximated)"],"metadata":{"id":"d_nPkBoB5jzo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bqpbEUfKUuOr"},"source":["# Part 3: The actual exercise. Generate the data to train your own network\n","In this part of the exercise you are supposed to complete the code for the dataloader below, so you can generate the data, which is need to train the network in Part 4 of the exercise"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OPBRsEu7_ju9"},"outputs":[],"source":["# ---------------------------------------------------------------------------- #\n","# Class for handling sampling data for ssdf\n","#\n","# mesh_list             list - A list of PyGEL3D meshes (the meshes that you want the network to approximate the SDF of)\n","# no_surface_points     int - The number of points to be sampled near the surface of the shape\n","# no_box_points         int - The number of points to be sampled in the bounding box of the shape\n","# mu                    float - The mean of the multivariate normal distribution, from which we sample a normal vector used to offset the sampled points on the surface\n","# sigma                 float - The standard deviation of the multivariate normal distribution, from which we sample a normal vector used to offset the sampled points on the surface\n","# ---------------------------------------------------------------------------- #\n","class meshData(Dataset):\n","    \"\"\"Mesh dataset.\"\"\"\n","\n","    def __init__(self, mesh_list : list, no_surface_points : int, no_box_points : int, mu : float, sigma : float) -> None:\n","\n","        self.mesh_list = mesh_list\n","        self.mesh_distances = []\n","        for mesh in mesh_list:\n","            self.mesh_distances.append(hmesh.MeshDistance(mesh))\n","\n","        # YOUR CODE HERE\n","        #----------------------------------------\n","        # Create the triangle_sdf array to sample the index of a triangle face uniformly\n","        self.triangle_cdf = []\n","\n","        self.num_surface_points = no_surface_points\n","        self.num_box_points = no_box_points\n","        self.mu_normal_vector = mu\n","        self.sigma_normal_vector = sigma\n","\n","    def __len__(self):\n","        return len(self.mesh_list)\n","\n","    def __getitem__(self, idx):\n","        # So if you provide the index as a tensor, which you would do, when you sample,\n","        # then this is converted to a list.\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        # Find the mesh and signed distance field by using the idx.\n","        mesh = self.mesh_list[idx]\n","        mesh_dist = self.mesh_distances[idx]\n","\n","        # YOUR CODE HERE\n","        #----------------------------------------\n","        # Sample the points close to the surface of the mesh and in the box from [-1,-1,-1] to [1,1,1], which encloses the surface\n","\n","        # ------------------------------------------\n","        # 3D points\n","        # ------------------------------------------\n","        points3d = []\n","\n","        points3d = np.array(points3d)\n","\n","        # ------------------------------------------\n","        # sdf - Signed Distance Field\n","        # ------------------------------------------\n","        sdf_values = mesh_dist.signed_distance(points3d).reshape((len(points3d),1)) # Compute the SDF of the sampled 3D points\n","        sdf_values = torch.from_numpy(sdf_values).float() # Convert to PyTorch Tensor\n","        points3d = torch.from_numpy(points3d) # Convert to PyTorch Tensor\n","\n","        sample = {'shape_id': idx, 'points3d': points3d, 'sdf_values': sdf_values}\n","\n","        return sample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HM2mNXsvUuOs"},"outputs":[],"source":["# Debugging - Make sure that the point cloud is sampled around the mesh\n","mesh_list = [m_bunny, m_wolf]\n","meshDataset = meshData(mesh_list=mesh_list,\n","                       no_surface_points = no_sampled_surface_points,\n","                       no_box_points=no_sampled_bounding_box_points,\n","                       mu=0.0, sigma=0.05)\n","\n","# Display the points together with the mesh. Is the result as you expected?\n","display_mesh_and_points(mesh_list[0], meshDataset[0]['points3d'].detach().numpy())"]},{"cell_type":"markdown","metadata":{"id":"CQCClMx6UuOt"},"source":["# Part 4: Train the network\n","In this part of the exercise you are supposed to train the network yourself - The code has already been writtne, so you should simply run the next cells of code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qOeOuZEW_ry2"},"outputs":[],"source":["mesh_list = [m_bunny, m_wolf]\n","meshDataset = meshData(mesh_list=mesh_list,\n","                       no_surface_points = no_sampled_surface_points,\n","                       no_box_points=no_sampled_bounding_box_points,\n","                       mu=0.0, sigma=0.05)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bcL5n17x_r1n"},"outputs":[],"source":["dataloader = DataLoader(meshDataset, batch_size=1, shuffle=True, num_workers=2, pin_memory=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G5a39cgv_4mC"},"outputs":[],"source":["# Network\n","net = Network(input_size=latent_vector_size + 3, hidden_layers=network_hidden_layers, device=device)\n","net = net.to(device)\n","# Latent vectors\n","lv = Latent_vectors(0.0, 0.01, latent_vector_size, 2, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DrtbxMME_4zB"},"outputs":[],"source":["# Optimizer\n","net_optimizer = optim.Adam(net.parameters(), lr=network_leanring_rate)\n","latent_vector_optimizer = optim.Adam([lv.latent_vectors], lr=latent_vector_learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2UPJ2lFf_47I"},"outputs":[],"source":["# Loss function\n","L1_loss = nn.L1Loss(reduction='sum')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pT2_gu9x_49_"},"outputs":[],"source":["# -----------------------------\n","# Note: You should get a quite good neural representation, if you use the hyper parameters above and train for approximiately 1200 epochs.\n","# -----------------------------\n","\n","min_loss = math.inf\n","# To make sure that you do not overwrite your best model, import your model and find the minimum loss.\n","if os.path.exists(your_best_model):\n","    checkpoint = torch.load(your_best_model,map_location=device)\n","    min_loss = checkpoint['loss']\n","losses = []\n","iteration = []\n","\n","for epoch in range(num_epochs):\n","    current_loss = 0.0\n","\n","    net.train()\n","    for i, batch in enumerate(dataloader):\n","        # Zero the network and latent vector gradients\n","        net_optimizer.zero_grad()\n","        latent_vector_optimizer.zero_grad()\n","\n","        # Get data from dataloader\n","        mesh_index, batch_points3d, batch_target = batch['shape_id'][0], batch['points3d'][0].to(device), batch['sdf_values'][0].to(device)\n","        N = batch_points3d.shape[0]\n","        # Concatenate the batch of 3d points with the latent vector\n","        net_input = torch.cat((batch_points3d, lv.latent_vectors[mesh_index].repeat(N, 1)), axis=1).float().to(device)\n","        # Feed the data through the network\n","        net_output = net.train_forward(net_input)\n","\n","        # Compute the batch loss\n","        batch_loss = L1_loss(net_output, batch_target) + lipschitz_cosntant * net.get_lipshitz_loss().to(device)\n","\n","        # Compute the gradients\n","        batch_loss.backward()\n","\n","        # Take a step with the optimizer\n","        net_optimizer.step()\n","        latent_vector_optimizer.step()\n","\n","        current_loss += float(batch_loss)\n","\n","    #---------------------------------------\n","    # Save best model as your_best_model.pt\n","    #---------------------------------------\n","    if current_loss < min_loss:\n","        min_loss = current_loss\n","        torch.save({\n","            'epoch': epoch,\n","            'net_state_dict': net.state_dict(),\n","            'latent_vectors': lv.latent_vectors,\n","            'net_optimizer_state_dict': net_optimizer.state_dict(),\n","            'loss': current_loss,\n","        },your_best_model)\n","\n","    #----------------------------------\n","    # Display the training error\n","    #----------------------------------\n","    losses.append(current_loss) # All batch losses\n","    iteration.append(epoch)\n","    plt.plot(iteration,losses,color='black')\n","    display.clear_output(wait=True)\n","    plt.grid()\n","    display.display(plt.gcf())\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.title(\"Training Loss\")\n","    #time.sleep(0.1)\n","    plt.grid()\n","    display.clear_output(wait=True)"]},{"cell_type":"markdown","metadata":{"id":"ZMH_p1DiDafH"},"source":["## Part 5: Questions\n","\n","1. How do we convert the neural implicit representation to a triangle mesh?\n","> Answer:\n","\n","2.   Why is it only possible to use watertight meshes?\n","> Answer:\n","\n","3.   What are the hyper parameters and what influence do they have?\n","> Answer:\n","\n","4. What does the Lipschitz regularization do?\n","> Answer:\n","\n","5. Do the recovered surfaces differ a lot from the true surfaces? If so, why?\n","> Answer:\n","\n","\n","## Non mandatory assignment\n","1. Try to not include the Lipschitz term in the loss and see what effect it has on the shape approximation\n","\n","2. Try experimenting with the size of the latent vector? Do you get better representations, when the latent vector is greater in size?\n","\n","3. Try to train the network on all three shapes or perhaps your own shapes. How do you interpolate between three shapes?\n","\n","4. Render images of the meshes that you obtained from the interpolation in e.g. Blender, and turn the images into a GIF/small movie using the python script:\n","images_to_gif.py from Learn."]},{"cell_type":"code","source":[],"metadata":{"id":"a1eWBeVybzwV"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"}},"nbformat":4,"nbformat_minor":0}